{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3503815-58bc-48c9-bc57-576124c94a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elastic net linear regression uses the penalties from both the lasso and ridge techniques to regularize regression models.\\n   The technique combines both the lasso and ridge regression methods by learning from their shortcomings to improve the\\n   regularization of statistical models.\\n    In other word, it is used for both reducing overfitting and feature selection.\\n   Elastic net regression differ from other regression :\\n     Elastic net is a hybrid of ridge regression and lasso regularization. Like lasso, elastic net can generate reduced models\\n     by generating zero-valued coefficients. Empirical studies have suggested that the elastic net technique can outperform \\n     lasso on data with highly correlated predictors.\\n    '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "'''Elastic net linear regression uses the penalties from both the lasso and ridge techniques to regularize regression models.\n",
    "   The technique combines both the lasso and ridge regression methods by learning from their shortcomings to improve the\n",
    "   regularization of statistical models.\n",
    "    In other word, it is used for both reducing overfitting and feature selection.\n",
    "   Elastic net regression differ from other regression :\n",
    "     Elastic net is a hybrid of ridge regression and lasso regularization. Like lasso, elastic net can generate reduced models\n",
    "     by generating zero-valued coefficients. Empirical studies have suggested that the elastic net technique can outperform \n",
    "     lasso on data with highly correlated predictors.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cba1097f-3bae-42b9-aeed-5295c0ee2d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Simply put, if you plug in 0 for alpha, the penalty function reduces to the L1 (ridge) term and if we set alpha to 1 we get\\n   the L2 (lasso) term. Therefore we can choose an alpha value between 0 and 1 to optimize the elastic net.\\n   Elastic Net first emerged as a result of critique on lasso, whose variable selection can be too dependent on data and thus\\n   unstable. The solution is to combine the penalties of ridge regression and lasso to get the best of both worlds. Elastic \\n   Net aims at minimizing the following loss function:\\n   \\nL- enet(beta^)= sum(i=1 to n) (yi - xibeta^)^2/2n + lambda(((1-alpha)/2 sum (J=1 to m)beta^j^2 +\\n                                                                                           alpha sqrt(sum (J=1 to m)beta^j^2)))\\n\\nfunction\\nwhere α is the mixing parameter between ridge (α\\u2004=\\u20040) and lasso (α\\u2004=\\u20041).\\n\\nNow, there are two parameters to tune: λ and α. The glmnet package allows to tune λ via cross-validation for a fixed α,\\nbut it does not support α-tuning, so we will turn to caret for this job.\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "'''Simply put, if you plug in 0 for alpha, the penalty function reduces to the L1 (ridge) term and if we set alpha to 1 we get\n",
    "   the L2 (lasso) term. Therefore we can choose an alpha value between 0 and 1 to optimize the elastic net.\n",
    "   Elastic Net first emerged as a result of critique on lasso, whose variable selection can be too dependent on data and thus\n",
    "   unstable. The solution is to combine the penalties of ridge regression and lasso to get the best of both worlds. Elastic \n",
    "   Net aims at minimizing the following loss function:\n",
    "   \n",
    "L- enet(beta^)= sum(i=1 to n) (yi - xibeta^)^2/2n + lambda(((1-alpha)/2 sum (J=1 to m)beta^j^2 +\n",
    "                                                                                           alpha sqrt(sum (J=1 to m)beta^j^2)))\n",
    "\n",
    "function\n",
    "where α is the mixing parameter between ridge (α = 0) and lasso (α = 1).\n",
    "\n",
    "Now, there are two parameters to tune: λ and α. The glmnet package allows to tune λ via cross-validation for a fixed α,\n",
    "but it does not support α-tuning, so we will turn to caret for this job.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8458e896-583b-4700-be71-a62903973ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'advantages of Elastic-Net regression:\\n   The benefit is that elastic net allows a balance of both penalties, which can result in better performance than a model \\n   with either one or the other penalty on some problems. Another hyperparameter is provided called “lambda” that controls \\n   the weighting of the sum of both penalties to the loss function.\\n   disadvantage of Elastic-Net regression:\\n   the sequential cross-validation procedure used to determine the penalty parameters results in overshrinkage of the\\n   coefficients.\\n   '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "'''advantages of Elastic-Net regression:\n",
    "   The benefit is that elastic net allows a balance of both penalties, which can result in better performance than a model \n",
    "   with either one or the other penalty on some problems. Another hyperparameter is provided called “lambda” that controls \n",
    "   the weighting of the sum of both penalties to the loss function.\n",
    "   disadvantage of Elastic-Net regression:\n",
    "   the sequential cross-validation procedure used to determine the penalty parameters results in overshrinkage of the\n",
    "   coefficients.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a306203e-8588-4089-b6be-263f4e86d9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use elastic net when you have several highly correlated variables. lasso provides elastic net regularization when you set \\n   the Alpha name-value pair to a number strictly between 0 and 1. See Lasso and Elastic Net Details.\\n   For lasso regularization of regression ensembles, see regularize.\\n   The elastic net framework is thus attractive for both variable selection and prediction, and can be adapted to\\n   classification problems, e.g., by applying classification rules to a penalized/Bayesian logistic regression.\\n   '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4\n",
    "'''Use elastic net when you have several highly correlated variables. lasso provides elastic net regularization when you set \n",
    "   the Alpha name-value pair to a number strictly between 0 and 1. See Lasso and Elastic Net Details.\n",
    "   For lasso regularization of regression ensembles, see regularize.\n",
    "   The elastic net framework is thus attractive for both variable selection and prediction, and can be adapted to\n",
    "   classification problems, e.g., by applying classification rules to a penalized/Bayesian logistic regression.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96260b0d-d24f-4729-9efd-75e8d8e3696a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A positive coefficient indicates that as the value of the independent variable increases, the mean of the dependent\\n   variable also tends to increase. A negative coefficient suggests that as the independent variable increases, the\\n   dependent variable tends to decrease. \\n   Interpreting the Coefficient of a Categorical Predictor Variable. For a categorical predictor variable, the \\n   regression coefficient represents the difference in the predicted value of the response variable between the category \\n   for which the predictor variable = 0 and the category for which the predictor variable = 1.\\n   '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5\n",
    "'''A positive coefficient indicates that as the value of the independent variable increases, the mean of the dependent\n",
    "   variable also tends to increase. A negative coefficient suggests that as the independent variable increases, the\n",
    "   dependent variable tends to decrease. \n",
    "   Interpreting the Coefficient of a Categorical Predictor Variable. For a categorical predictor variable, the \n",
    "   regression coefficient represents the difference in the predicted value of the response variable between the category \n",
    "   for which the predictor variable = 0 and the category for which the predictor variable = 1.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4c3fa0a-f629-4319-95e5-a62046736169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Simple approaches include taking the average of the column and use that value, or if there is a heavy skew the median\\n   might be better. A better approach, you can perform regression or nearest neighbor imputation on the column to predict\\n   the missing values. Then continue on with your analysis/model.\\n   '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6\n",
    "'''Simple approaches include taking the average of the column and use that value, or if there is a heavy skew the median\n",
    "   might be better. A better approach, you can perform regression or nearest neighbor imputation on the column to predict\n",
    "   the missing values. Then continue on with your analysis/model.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d14f1b4-0e22-464f-8b18-13f39f4454ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" ELASTIC NET perform feature selection and that's their whole purpose, so yes you can use them for this. You don't \\n    need to select top n features, since you can play with the arguments α and λ to get an arbitrary number of \\n    non-negative coefficients.\\n    \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7\n",
    "''' ELASTIC NET perform feature selection and that's their whole purpose, so yes you can use them for this. You don't \n",
    "    need to select top n features, since you can play with the arguments α and λ to get an arbitrary number of \n",
    "    non-negative coefficients.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79d76c78-c14d-4860-ae70-06bd534fb088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the pickle module implements binary protocols for serializing kand de-serializing a python objecct structure. \"Pickling\"\\n   is the process whereby a python object hierarchy is converted into a byte stream and \"unpickling\" is the inverse operation,\\n   whereby a byte stream (from a binary file or bytes-like object) is converted back into an object hierarchy. Pickling  \\n   (and unpickling) is alternatively known as serialization, marshalling, 1 or flattening : however, to avoid confusion.\\n   the terms used here are pickling and unpickling.\\n\\n  pickle in python is primarily used in serializing and deserializing a python object structure. In other words, it\\'s the \\n  process of converting a python object into a byte stream to store it in a file/database, maintain program state acrooss\\n  sessions, ortransport data over thhe network.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8\n",
    "'''the pickle module implements binary protocols for serializing kand de-serializing a python objecct structure. \"Pickling\"\n",
    "   is the process whereby a python object hierarchy is converted into a byte stream and \"unpickling\" is the inverse operation,\n",
    "   whereby a byte stream (from a binary file or bytes-like object) is converted back into an object hierarchy. Pickling  \n",
    "   (and unpickling) is alternatively known as serialization, marshalling, 1 or flattening : however, to avoid confusion.\n",
    "   the terms used here are pickling and unpickling.\n",
    "\n",
    "  pickle in python is primarily used in serializing and deserializing a python object structure. In other words, it's the \n",
    "  process of converting a python object into a byte stream to store it in a file/database, maintain program state acrooss\n",
    "  sessions, ortransport data over thhe network.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f465255-a043-4fe9-8302-1bb3e062b037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pickle is a useful Python tool that allows you to save your ML models, to minimise lengthy re-training and allow you to \\n   share, commit, and re-load pre-trained machine learning models. Most data scientists working in ML will use Pickle or \\n   Joblib to save their ML model for future use.\\n   '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q9\n",
    "'''Pickle is a useful Python tool that allows you to save your ML models, to minimise lengthy re-training and allow you to \n",
    "   share, commit, and re-load pre-trained machine learning models. Most data scientists working in ML will use Pickle or \n",
    "   Joblib to save their ML model for future use.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147e419-d01e-4969-8abb-3185874a8633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
